{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCoRy+Jg3T5cFRh4apWtYK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YAMAZAKIAkiraRK/GCAnet/blob/main/DataAugTest_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FVcPZTr3T0s",
        "outputId": "24c1fa5a-4f3c-45c0-a013-5ffdd812c4e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/GCA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSMoqyJtPIqh",
        "outputId": "565d10ba-eda7-4573-e363-13ba32f8e213"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/GCA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4eTP13Gj3D5m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn.preprocessing as sp\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import preprocess as pp\n",
        "import Grad_Cam as gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#訓練データの読み込み\n",
        "p_dir = \"YU/grating image/202207/GC2022\"\n",
        "c_dir = os.listdir(p_dir)\n",
        "i = 0\n",
        "data=[]\n",
        "label=[]\n",
        "label_name = []\n",
        "\n",
        "for d in c_dir:\n",
        "    label_name.append(d)\n",
        "    d = os.path.join(p_dir, d)\n",
        "    pp.append_data(d, data, label, i)\n",
        "    i += 1\n",
        "label = np.array(label).reshape(-1,1)\n",
        "#ラベルをone_hot_encoding\n",
        "enc = sp.OneHotEncoder(categories=\"auto\", sparse_output=False, dtype=np.float32)\n",
        "label_enc = enc.fit_transform(label)\n",
        "\n",
        "\n",
        "#テストデータの読み込み\n",
        "p_dir = \"YU/grating image/202207/test data\"\n",
        "c_dir = os.listdir(p_dir)\n",
        "i = 0\n",
        "test_data=[]\n",
        "test_label=[]\n",
        "test_label_name = []\n",
        "for d in c_dir:\n",
        "    test_label_name.append(d)\n",
        "    d = os.path.join(p_dir, d)\n",
        "    pp.append_data(d, test_data, test_label, i)\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "sFrBZFSj3Tzk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前処理-アスペクト比は気にせず299,299に縮小\n",
        "#訓練データ\n",
        "shrink_data = np.empty((len(data),299,299,3))\n",
        "for i in range(len(data)):\n",
        "    shrink_data[i]=cv2.resize(data[i], dsize=(299, 299))\n",
        "shrink_data = np.array(shrink_data)\n",
        "\n",
        "#テストデータ\n",
        "shrink_test_data = np.empty((len(test_data),299,299,3))\n",
        "for i in range(len(test_data)):\n",
        "    shrink_test_data[i]=cv2.resize(test_data[i], dsize=(299, 299))\n",
        "shrink_test_data = np.array(shrink_test_data)"
      ],
      "metadata": {
        "id": "o1xpn__xBjSq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'rotation_range': 15,\n",
        "    'vertical_flip': True,\n",
        "    'horizontal_flip': True,\n",
        "    'height_shift_range': 0.05,\n",
        "    'width_shift_range': 0.05,\n",
        "    'channel_shift_range': 127,\n",
        "    'zoom_range': [0.05, 1.0],\n",
        "}"
      ],
      "metadata": {
        "id": "bNGZurwYC0h_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gengenerator(data, label, param):\n",
        "    train_data, val_data, train_label, val_label = train_test_split(data, label, random_state=1, stratify = label)\n",
        "    data_gen = keras.preprocessing.image.ImageDataGenerator(param)\n",
        "    data_gen.fit(data)\n",
        "    train_generator = data_gen.flow(train_data, train_label, batch_size=32)\n",
        "    val_generator = data_gen.flow(val_data, val_label)\n",
        "    return train_generator, val_generator"
      ],
      "metadata": {
        "id": "sxQPeD2bC2uj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#パラメータを渡し、正答率を返す関数\n",
        "def DAcomparison(data, label, test_data, test_label, params):\n",
        "    models=[]\n",
        "    histories=[]\n",
        "    preds=[]\n",
        "    accuracies = []\n",
        "    for key, val in params.items():\n",
        "        param = {key:val}\n",
        "\n",
        "        train_generator, val_generator  = gengenerator(data, label, param)\n",
        "\n",
        "        #GoogLeNetを読み込み、出力層の数を6に変更\n",
        "        base_model = InceptionV3(weights=\"imagenet\", input_shape=(299, 299,3) ,include_top=False)\n",
        "        x = base_model.output\n",
        "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "        predictions = Dense(6, activation=\"softmax\")(x)\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        #モデルのコンパイル\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "        train_data, val_data, train_label, val_label = train_test_split(data, label_enc, random_state=1, stratify = label)\n",
        "        data_gen = keras.preprocessing.image.ImageDataGenerator(param)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        history = model.fit_generator(data_gen.flow(train_data, train_label, batch_size=4),\n",
        "                                      steps_per_epoch = len(train_data)/4,\n",
        "                                      validation_data = data_gen.flow(val_data, val_label),\n",
        "                                      epochs=120, verbose=1)\n",
        "        models.append(model)\n",
        "        histories.append(history)\n",
        "        prediction = np.argmax(model.predict(test_data),axis=1)\n",
        "        preds.append(prediction)\n",
        "        accuracy = sum(test_label==prediction) / len(test_label)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    return models, histories, preds, accuracies"
      ],
      "metadata": {
        "id": "wTC9qKyRC3Rg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models, histories, predictions, accuracies = DAcomparison(\n",
        "    data=shrink_data, label=label, test_data=shrink_test_data, test_label=test_label, params=params\n",
        ")"
      ],
      "metadata": {
        "id": "5UVzHGP_DD21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2b7e1a-e9ab-4bdd-8b4b-73bbc1eb6107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Epoch 1/120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-414dda0408a1>:29: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(data_gen.flow(train_data, train_label, batch_size=4),\n",
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 25s 2s/step - loss: 5.1723 - accuracy: 0.1220 - val_loss: 4.2097 - val_accuracy: 0.3571\n",
            "Epoch 2/120\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.0081 - accuracy: 0.2439 - val_loss: 2.6869 - val_accuracy: 0.2143\n",
            "Epoch 3/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.0484 - accuracy: 0.0976 - val_loss: 2.3398 - val_accuracy: 0.3571\n",
            "Epoch 4/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 1.8516 - accuracy: 0.2927 - val_loss: 1.9844 - val_accuracy: 0.5000\n",
            "Epoch 5/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 1.6207 - accuracy: 0.2927 - val_loss: 1.7682 - val_accuracy: 0.4286\n",
            "Epoch 6/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 1.4253 - accuracy: 0.3902 - val_loss: 1.6321 - val_accuracy: 0.5714\n",
            "Epoch 7/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 1.3438 - accuracy: 0.5122 - val_loss: 1.5458 - val_accuracy: 0.5714\n",
            "Epoch 8/120\n",
            "10/10 [==============================] - 15s 2s/step - loss: 1.2333 - accuracy: 0.6341 - val_loss: 1.3691 - val_accuracy: 0.7143\n",
            "Epoch 9/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 1.0424 - accuracy: 0.7073 - val_loss: 1.2790 - val_accuracy: 0.7143\n",
            "Epoch 10/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.9863 - accuracy: 0.7073 - val_loss: 1.2362 - val_accuracy: 0.5714\n",
            "Epoch 11/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.8621 - accuracy: 0.7317 - val_loss: 1.0575 - val_accuracy: 0.7143\n",
            "Epoch 12/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.7873 - accuracy: 0.8049 - val_loss: 0.9991 - val_accuracy: 0.7857\n",
            "Epoch 13/120\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.7253 - accuracy: 0.7805 - val_loss: 0.9051 - val_accuracy: 0.7857\n",
            "Epoch 14/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6923 - accuracy: 0.7561 - val_loss: 0.8595 - val_accuracy: 0.7857\n",
            "Epoch 15/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6415 - accuracy: 0.8293 - val_loss: 0.9054 - val_accuracy: 0.7857\n",
            "Epoch 16/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5946 - accuracy: 0.9268 - val_loss: 0.8130 - val_accuracy: 0.8571\n",
            "Epoch 17/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5706 - accuracy: 0.8293 - val_loss: 0.7967 - val_accuracy: 0.7857\n",
            "Epoch 18/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5513 - accuracy: 0.8780 - val_loss: 0.8277 - val_accuracy: 0.7857\n",
            "Epoch 19/120\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.5150 - accuracy: 0.9268 - val_loss: 0.7737 - val_accuracy: 0.8571\n",
            "Epoch 20/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.4748 - accuracy: 0.9024 - val_loss: 0.7253 - val_accuracy: 0.8571\n",
            "Epoch 21/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.4686 - accuracy: 0.8780 - val_loss: 0.6829 - val_accuracy: 0.8571\n",
            "Epoch 22/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.4254 - accuracy: 0.9268 - val_loss: 0.7112 - val_accuracy: 0.8571\n",
            "Epoch 23/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.4115 - accuracy: 0.9512 - val_loss: 0.7110 - val_accuracy: 0.8571\n",
            "Epoch 24/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.4071 - accuracy: 0.9268 - val_loss: 0.6518 - val_accuracy: 0.8571\n",
            "Epoch 25/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.3816 - accuracy: 0.9756 - val_loss: 0.6555 - val_accuracy: 0.8571\n",
            "Epoch 26/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.3567 - accuracy: 0.9756 - val_loss: 0.6428 - val_accuracy: 0.8571\n",
            "Epoch 27/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.3603 - accuracy: 0.9268 - val_loss: 0.6478 - val_accuracy: 0.8571\n",
            "Epoch 28/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.3407 - accuracy: 0.9756 - val_loss: 0.6028 - val_accuracy: 0.8571\n",
            "Epoch 29/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.3081 - accuracy: 0.9756 - val_loss: 0.6410 - val_accuracy: 0.8571\n",
            "Epoch 30/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.3128 - accuracy: 0.9756 - val_loss: 0.6649 - val_accuracy: 0.8571\n",
            "Epoch 31/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.2922 - accuracy: 0.9756 - val_loss: 0.5880 - val_accuracy: 0.8571\n",
            "Epoch 32/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.3080 - accuracy: 0.9756 - val_loss: 0.6058 - val_accuracy: 0.8571\n",
            "Epoch 33/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.2946 - accuracy: 0.9756 - val_loss: 0.5623 - val_accuracy: 0.8571\n",
            "Epoch 34/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.2836 - accuracy: 0.9756 - val_loss: 0.5655 - val_accuracy: 0.8571\n",
            "Epoch 35/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.2600 - accuracy: 0.9756 - val_loss: 0.6323 - val_accuracy: 0.8571\n",
            "Epoch 36/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.2671 - accuracy: 0.9756 - val_loss: 0.5325 - val_accuracy: 0.8571\n",
            "Epoch 37/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.2415 - accuracy: 0.9756 - val_loss: 0.5342 - val_accuracy: 0.8571\n",
            "Epoch 38/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.2364 - accuracy: 0.9756 - val_loss: 0.5208 - val_accuracy: 0.8571\n",
            "Epoch 39/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.2261 - accuracy: 0.9756 - val_loss: 0.5964 - val_accuracy: 0.8571\n",
            "Epoch 40/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.2279 - accuracy: 0.9756 - val_loss: 0.5789 - val_accuracy: 0.8571\n",
            "Epoch 41/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.2038 - accuracy: 0.9756 - val_loss: 0.5136 - val_accuracy: 0.8571\n",
            "Epoch 42/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.2104 - accuracy: 0.9756 - val_loss: 0.5130 - val_accuracy: 0.8571\n",
            "Epoch 43/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1980 - accuracy: 0.9756 - val_loss: 0.5241 - val_accuracy: 0.8571\n",
            "Epoch 44/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.1918 - accuracy: 0.9756 - val_loss: 0.4881 - val_accuracy: 0.8571\n",
            "Epoch 45/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1858 - accuracy: 0.9756 - val_loss: 0.5231 - val_accuracy: 0.8571\n",
            "Epoch 46/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1838 - accuracy: 0.9756 - val_loss: 0.5456 - val_accuracy: 0.8571\n",
            "Epoch 47/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.1743 - accuracy: 0.9756 - val_loss: 0.5028 - val_accuracy: 0.8571\n",
            "Epoch 48/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.1789 - accuracy: 0.9756 - val_loss: 0.4942 - val_accuracy: 0.8571\n",
            "Epoch 49/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1659 - accuracy: 0.9756 - val_loss: 0.5201 - val_accuracy: 0.8571\n",
            "Epoch 50/120\n",
            "10/10 [==============================] - 14s 2s/step - loss: 0.1652 - accuracy: 0.9756 - val_loss: 0.5315 - val_accuracy: 0.8571\n",
            "Epoch 51/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.1578 - accuracy: 0.9756 - val_loss: 0.5013 - val_accuracy: 0.8571\n",
            "Epoch 52/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1520 - accuracy: 0.9756 - val_loss: 0.4856 - val_accuracy: 0.8571\n",
            "Epoch 53/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.1521 - accuracy: 0.9756 - val_loss: 0.5078 - val_accuracy: 0.8571\n",
            "Epoch 54/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.1463 - accuracy: 0.9756 - val_loss: 0.4944 - val_accuracy: 0.8571\n",
            "Epoch 55/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1455 - accuracy: 0.9756 - val_loss: 0.5126 - val_accuracy: 0.8571\n",
            "Epoch 56/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1383 - accuracy: 0.9756 - val_loss: 0.4697 - val_accuracy: 0.8571\n",
            "Epoch 57/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8571\n",
            "Epoch 58/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.8571\n",
            "Epoch 59/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.1316 - accuracy: 0.9756 - val_loss: 0.4914 - val_accuracy: 0.8571\n",
            "Epoch 60/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.1284 - accuracy: 0.9756 - val_loss: 0.4813 - val_accuracy: 0.8571\n",
            "Epoch 61/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.1251 - accuracy: 0.9756 - val_loss: 0.4818 - val_accuracy: 0.8571\n",
            "Epoch 62/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8571\n",
            "Epoch 63/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1221 - accuracy: 0.9756 - val_loss: 0.4853 - val_accuracy: 0.8571\n",
            "Epoch 64/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.8571\n",
            "Epoch 65/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8571\n",
            "Epoch 66/120\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8571\n",
            "Epoch 67/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8571\n",
            "Epoch 68/120\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8571\n",
            "Epoch 69/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8571\n",
            "Epoch 70/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.8571\n",
            "Epoch 71/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.1177 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8571\n",
            "Epoch 72/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8571\n",
            "Epoch 73/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8571\n",
            "Epoch 74/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8571\n",
            "Epoch 75/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8571\n",
            "Epoch 76/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.8571\n",
            "Epoch 77/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8571\n",
            "Epoch 78/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8571\n",
            "Epoch 79/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8571\n",
            "Epoch 80/120\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8571\n",
            "Epoch 81/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.8571\n",
            "Epoch 82/120\n",
            "10/10 [==============================] - 16s 1s/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.8571\n",
            "Epoch 83/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.8571\n",
            "Epoch 84/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8571\n",
            "Epoch 85/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8571\n",
            "Epoch 86/120\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8571\n",
            "Epoch 87/120\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8571\n",
            "Epoch 88/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8571\n",
            "Epoch 89/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8571\n",
            "Epoch 90/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.8571\n",
            "Epoch 91/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8571\n",
            "Epoch 92/120\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8571\n",
            "Epoch 93/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8571\n",
            "Epoch 94/120\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8571\n",
            "Epoch 95/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8571\n",
            "Epoch 96/120\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8571\n",
            "Epoch 97/120\n",
            "10/10 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[6]\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VH3Fr9hJLgYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "5efd8311-ca79-4637-d205-953db31dc567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-118cf36d9a8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[-1].activation = None\n",
        "img_path = \"shrink/shrink_testdata/shrink_testdata16.jpg\"\n",
        "img_array = gc.get_img_array(img_path)\n",
        "last_conv_layer_name = \"conv2d_657\"\n",
        "heatmap = gc.make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "gc.save_and_display_gradcam(img_path, heatmap, cam_path=\"cam6.jpg\")"
      ],
      "metadata": {
        "id": "YPPErj54LjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NonDAcomparison(data, label, test_data, test_label):\n",
        "\n",
        "  #GoogLeNetを読み込み、出力層の数を6に変更\n",
        "  base_model = InceptionV3(weights=\"imagenet\", input_shape=(299, 299,3) ,include_top=False)\n",
        "  x = base_model.output\n",
        "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "  predictions = Dense(6, activation=\"softmax\")(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  #モデルのコンパイル\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "  train_data, val_data, train_label, val_label = train_test_split(data, label, random_state=1, stratify = label)\n",
        "\n",
        "  history = model.fit(train_data, train_label, batch_size=4,\n",
        "                      steps_per_epoch = len(train_data)/4,\n",
        "                      validation_data = (val_data, val_label),\n",
        "                      epochs=300, verbose=1)\n",
        "  prediction = np.argmax(model.predict(test_data),axis=1)\n",
        "  accuracy = sum(test_label==prediction) / len(test_label)\n",
        "\n",
        "  return model, history, prediction, accuracy"
      ],
      "metadata": {
        "id": "NoEHNNqXZAzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NDAmodel, NDAhistory, NDAprediction, NDAaccuracy = NonDAcomparison(\n",
        "    data=shrink_data, label=label_enc, test_data=shrink_test_data, test_label=test_label\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsYN-vmcJWI",
        "outputId": "65fbec6d-4725-44cc-ded3-aa323e7058ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 7s 317ms/step - loss: 5.8078 - accuracy: 0.2927 - val_loss: 4.2452 - val_accuracy: 0.1429\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 4.4691 - accuracy: 0.1951 - val_loss: 3.5492 - val_accuracy: 0.1429\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 3.4944 - accuracy: 0.3415 - val_loss: 2.9523 - val_accuracy: 0.4286\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.7124 - accuracy: 0.4634 - val_loss: 2.1702 - val_accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.8561 - accuracy: 0.4878 - val_loss: 1.4992 - val_accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 1.2399 - accuracy: 0.4634 - val_loss: 1.3502 - val_accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 1.1498 - accuracy: 0.5610 - val_loss: 1.2028 - val_accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.9305 - accuracy: 0.7561 - val_loss: 1.0951 - val_accuracy: 0.7143\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.8604 - accuracy: 0.7561 - val_loss: 1.0901 - val_accuracy: 0.7857\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.8073 - accuracy: 0.7805 - val_loss: 0.9842 - val_accuracy: 0.7857\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.7333 - accuracy: 0.8049 - val_loss: 1.0046 - val_accuracy: 0.6429\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.7285 - accuracy: 0.7561 - val_loss: 1.0072 - val_accuracy: 0.7857\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6784 - accuracy: 0.8293 - val_loss: 0.9086 - val_accuracy: 0.7143\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.6433 - accuracy: 0.8293 - val_loss: 0.8196 - val_accuracy: 0.7143\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.6157 - accuracy: 0.8537 - val_loss: 0.8446 - val_accuracy: 0.7857\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5755 - accuracy: 0.8780 - val_loss: 0.8665 - val_accuracy: 0.7857\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5644 - accuracy: 0.7805 - val_loss: 0.7925 - val_accuracy: 0.7857\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.5288 - accuracy: 0.9024 - val_loss: 0.7927 - val_accuracy: 0.7857\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.5042 - accuracy: 0.8537 - val_loss: 0.7467 - val_accuracy: 0.7857\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.4813 - accuracy: 0.9024 - val_loss: 0.7610 - val_accuracy: 0.7857\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4512 - accuracy: 0.8780 - val_loss: 0.7675 - val_accuracy: 0.7857\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4473 - accuracy: 0.9268 - val_loss: 0.6951 - val_accuracy: 0.7857\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4315 - accuracy: 0.8780 - val_loss: 0.6738 - val_accuracy: 0.7857\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4164 - accuracy: 0.9024 - val_loss: 0.6866 - val_accuracy: 0.7857\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4002 - accuracy: 0.9512 - val_loss: 0.7137 - val_accuracy: 0.7857\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4005 - accuracy: 0.9024 - val_loss: 0.6717 - val_accuracy: 0.7857\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3818 - accuracy: 0.9024 - val_loss: 0.6813 - val_accuracy: 0.7857\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3668 - accuracy: 0.9268 - val_loss: 0.6330 - val_accuracy: 0.7857\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3495 - accuracy: 0.9512 - val_loss: 0.6127 - val_accuracy: 0.7857\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3816 - accuracy: 0.8537 - val_loss: 0.5873 - val_accuracy: 0.8571\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.3275 - accuracy: 0.9024 - val_loss: 0.5973 - val_accuracy: 0.8571\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.3248 - accuracy: 0.9512 - val_loss: 0.6536 - val_accuracy: 0.7857\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3063 - accuracy: 0.9512 - val_loss: 0.5818 - val_accuracy: 0.8571\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3122 - accuracy: 0.9268 - val_loss: 0.5411 - val_accuracy: 0.8571\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3002 - accuracy: 0.9268 - val_loss: 0.5678 - val_accuracy: 0.7857\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2793 - accuracy: 0.9756 - val_loss: 0.5488 - val_accuracy: 0.8571\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2785 - accuracy: 0.9512 - val_loss: 0.5719 - val_accuracy: 0.8571\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2671 - accuracy: 0.9756 - val_loss: 0.5503 - val_accuracy: 0.8571\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2719 - accuracy: 0.9512 - val_loss: 0.5124 - val_accuracy: 0.8571\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.2550 - accuracy: 0.9512 - val_loss: 0.5445 - val_accuracy: 0.8571\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2445 - accuracy: 0.9756 - val_loss: 0.5503 - val_accuracy: 0.7857\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2391 - accuracy: 0.9756 - val_loss: 0.4859 - val_accuracy: 0.8571\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2456 - accuracy: 0.9756 - val_loss: 0.4928 - val_accuracy: 0.8571\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2481 - accuracy: 0.9268 - val_loss: 0.4868 - val_accuracy: 0.8571\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2294 - accuracy: 0.9756 - val_loss: 0.5222 - val_accuracy: 0.8571\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2248 - accuracy: 0.9756 - val_loss: 0.5075 - val_accuracy: 0.8571\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.2215 - accuracy: 0.9756 - val_loss: 0.4762 - val_accuracy: 0.8571\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.2184 - accuracy: 0.9756 - val_loss: 0.4916 - val_accuracy: 0.8571\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2082 - accuracy: 0.9756 - val_loss: 0.4745 - val_accuracy: 0.8571\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1989 - accuracy: 0.9756 - val_loss: 0.4834 - val_accuracy: 0.8571\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1970 - accuracy: 0.9756 - val_loss: 0.4809 - val_accuracy: 0.8571\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.1960 - accuracy: 0.9756 - val_loss: 0.4689 - val_accuracy: 0.8571\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1916 - accuracy: 0.9756 - val_loss: 0.4636 - val_accuracy: 0.8571\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1818 - accuracy: 0.9756 - val_loss: 0.4355 - val_accuracy: 0.8571\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1861 - accuracy: 0.9756 - val_loss: 0.4549 - val_accuracy: 0.8571\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1740 - accuracy: 0.9756 - val_loss: 0.4331 - val_accuracy: 0.8571\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.1853 - accuracy: 0.9756 - val_loss: 0.4372 - val_accuracy: 0.8571\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2262 - accuracy: 0.9512 - val_loss: 0.4085 - val_accuracy: 0.9286\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1926 - accuracy: 0.9756 - val_loss: 0.4294 - val_accuracy: 0.8571\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1791 - accuracy: 0.9756 - val_loss: 0.4730 - val_accuracy: 0.8571\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1643 - accuracy: 0.9756 - val_loss: 0.4559 - val_accuracy: 0.8571\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.1566 - accuracy: 0.9756 - val_loss: 0.4318 - val_accuracy: 0.8571\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1574 - accuracy: 0.9756 - val_loss: 0.4066 - val_accuracy: 0.9286\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1490 - accuracy: 0.9756 - val_loss: 0.4150 - val_accuracy: 0.8571\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1525 - accuracy: 0.9756 - val_loss: 0.4251 - val_accuracy: 0.8571\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1585 - accuracy: 0.9756 - val_loss: 0.3603 - val_accuracy: 0.8571\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1519 - accuracy: 0.9756 - val_loss: 0.4194 - val_accuracy: 0.8571\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1474 - accuracy: 0.9756 - val_loss: 0.4527 - val_accuracy: 0.8571\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.1451 - accuracy: 0.9756 - val_loss: 0.4302 - val_accuracy: 0.8571\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1329 - accuracy: 0.9756 - val_loss: 0.3935 - val_accuracy: 0.9286\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.1370 - accuracy: 0.9756 - val_loss: 0.4022 - val_accuracy: 0.8571\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1320 - accuracy: 0.9756 - val_loss: 0.4042 - val_accuracy: 0.8571\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1337 - accuracy: 0.9756 - val_loss: 0.3912 - val_accuracy: 0.8571\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.1266 - accuracy: 0.9756 - val_loss: 0.3831 - val_accuracy: 0.8571\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1244 - accuracy: 0.9756 - val_loss: 0.4007 - val_accuracy: 0.8571\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1228 - accuracy: 0.9756 - val_loss: 0.4011 - val_accuracy: 0.8571\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1240 - accuracy: 0.9756 - val_loss: 0.3913 - val_accuracy: 0.8571\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1185 - accuracy: 0.9756 - val_loss: 0.3904 - val_accuracy: 0.9286\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1202 - accuracy: 0.9756 - val_loss: 0.3806 - val_accuracy: 0.9286\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1201 - accuracy: 0.9756 - val_loss: 0.3713 - val_accuracy: 0.9286\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1133 - accuracy: 0.9756 - val_loss: 0.3819 - val_accuracy: 0.8571\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1141 - accuracy: 0.9756 - val_loss: 0.4046 - val_accuracy: 0.8571\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1122 - accuracy: 0.9756 - val_loss: 0.3948 - val_accuracy: 0.8571\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1111 - accuracy: 0.9756 - val_loss: 0.3723 - val_accuracy: 0.8571\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1117 - accuracy: 0.9756 - val_loss: 0.3408 - val_accuracy: 0.9286\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1070 - accuracy: 0.9756 - val_loss: 0.4032 - val_accuracy: 0.7857\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.1172 - accuracy: 0.9756 - val_loss: 0.3826 - val_accuracy: 0.8571\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1184 - accuracy: 0.9756 - val_loss: 0.3542 - val_accuracy: 0.9286\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1110 - accuracy: 0.9756 - val_loss: 0.3601 - val_accuracy: 0.8571\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0987 - accuracy: 0.9756 - val_loss: 0.3637 - val_accuracy: 0.8571\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0992 - accuracy: 0.9756 - val_loss: 0.3414 - val_accuracy: 0.9286\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1013 - accuracy: 0.9756 - val_loss: 0.3602 - val_accuracy: 0.9286\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0984 - accuracy: 0.9756 - val_loss: 0.3733 - val_accuracy: 0.8571\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0987 - accuracy: 0.9756 - val_loss: 0.3687 - val_accuracy: 0.8571\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0981 - accuracy: 0.9756 - val_loss: 0.3447 - val_accuracy: 0.9286\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0960 - accuracy: 0.9756 - val_loss: 0.3838 - val_accuracy: 0.8571\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0970 - accuracy: 0.9756 - val_loss: 0.3677 - val_accuracy: 0.8571\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0957 - accuracy: 0.9756 - val_loss: 0.3223 - val_accuracy: 0.9286\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0931 - accuracy: 0.9756 - val_loss: 0.3433 - val_accuracy: 0.9286\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0941 - accuracy: 0.9756 - val_loss: 0.3488 - val_accuracy: 0.9286\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0891 - accuracy: 0.9756 - val_loss: 0.3173 - val_accuracy: 0.9286\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0856 - accuracy: 0.9756 - val_loss: 0.3402 - val_accuracy: 0.9286\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0851 - accuracy: 0.9756 - val_loss: 0.3447 - val_accuracy: 0.9286\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0870 - accuracy: 0.9756 - val_loss: 0.3276 - val_accuracy: 0.9286\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0902 - accuracy: 0.9756 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0901 - accuracy: 0.9756 - val_loss: 0.3654 - val_accuracy: 0.9286\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0842 - accuracy: 0.9756 - val_loss: 0.3242 - val_accuracy: 0.9286\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0815 - accuracy: 0.9756 - val_loss: 0.3202 - val_accuracy: 0.8571\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 0.3270 - val_accuracy: 0.9286\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0782 - accuracy: 0.9756 - val_loss: 0.3153 - val_accuracy: 0.9286\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0778 - accuracy: 0.9756 - val_loss: 0.3186 - val_accuracy: 0.9286\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 0.3097 - val_accuracy: 0.9286\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0777 - accuracy: 0.9756 - val_loss: 0.3085 - val_accuracy: 0.9286\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0738 - accuracy: 0.9756 - val_loss: 0.3331 - val_accuracy: 0.8571\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0771 - accuracy: 0.9756 - val_loss: 0.3373 - val_accuracy: 0.8571\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0742 - accuracy: 0.9756 - val_loss: 0.3238 - val_accuracy: 0.9286\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 0.3146 - val_accuracy: 0.9286\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0731 - accuracy: 0.9756 - val_loss: 0.3099 - val_accuracy: 0.9286\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0723 - accuracy: 0.9756 - val_loss: 0.3228 - val_accuracy: 0.9286\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.3604 - val_accuracy: 0.9286\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0762 - accuracy: 0.9756 - val_loss: 0.3353 - val_accuracy: 0.9286\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.3163 - val_accuracy: 0.9286\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0715 - accuracy: 0.9756 - val_loss: 0.2958 - val_accuracy: 0.9286\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0733 - accuracy: 0.9756 - val_loss: 0.3243 - val_accuracy: 0.9286\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 0.0674 - accuracy: 0.9756 - val_loss: 0.3285 - val_accuracy: 0.8571\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.0652 - accuracy: 0.9756 - val_loss: 0.3098 - val_accuracy: 0.9286\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0795 - accuracy: 0.9756 - val_loss: 0.2543 - val_accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.0834 - accuracy: 0.9756 - val_loss: 0.2628 - val_accuracy: 0.9286\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9286\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0670 - accuracy: 0.9756 - val_loss: 0.3170 - val_accuracy: 0.9286\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.0656 - accuracy: 0.9756 - val_loss: 0.3198 - val_accuracy: 0.9286\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0636 - accuracy: 0.9756 - val_loss: 0.3053 - val_accuracy: 0.9286\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0608 - accuracy: 0.9756 - val_loss: 0.2917 - val_accuracy: 0.9286\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0654 - accuracy: 0.9756 - val_loss: 0.2815 - val_accuracy: 0.9286\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0609 - accuracy: 0.9756 - val_loss: 0.2968 - val_accuracy: 0.9286\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0611 - accuracy: 0.9756 - val_loss: 0.2925 - val_accuracy: 0.9286\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0637 - accuracy: 0.9756 - val_loss: 0.3135 - val_accuracy: 0.9286\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0598 - accuracy: 0.9756 - val_loss: 0.3027 - val_accuracy: 0.9286\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9286\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9286\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0577 - accuracy: 0.9756 - val_loss: 0.2900 - val_accuracy: 0.9286\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0573 - accuracy: 0.9756 - val_loss: 0.2839 - val_accuracy: 0.9286\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0581 - accuracy: 0.9756 - val_loss: 0.3032 - val_accuracy: 0.9286\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0622 - accuracy: 0.9756 - val_loss: 0.2952 - val_accuracy: 0.8571\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0639 - accuracy: 0.9756 - val_loss: 0.3157 - val_accuracy: 0.9286\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0553 - accuracy: 0.9756 - val_loss: 0.2780 - val_accuracy: 0.9286\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9286\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9286\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.0588 - accuracy: 0.9756 - val_loss: 0.2974 - val_accuracy: 0.9286\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0555 - accuracy: 0.9756 - val_loss: 0.2871 - val_accuracy: 0.9286\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0525 - accuracy: 0.9756 - val_loss: 0.2810 - val_accuracy: 0.9286\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9286\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0529 - accuracy: 0.9756 - val_loss: 0.2797 - val_accuracy: 0.9286\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0538 - accuracy: 0.9756 - val_loss: 0.2923 - val_accuracy: 0.9286\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0545 - accuracy: 0.9756 - val_loss: 0.2719 - val_accuracy: 0.9286\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9286\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0773 - accuracy: 0.9756 - val_loss: 0.3803 - val_accuracy: 0.9286\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0699 - accuracy: 0.9756 - val_loss: 0.3044 - val_accuracy: 0.9286\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0519 - accuracy: 0.9756 - val_loss: 0.2778 - val_accuracy: 0.9286\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9286\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9286\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9286\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9286\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9286\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0521 - accuracy: 0.9756 - val_loss: 0.2969 - val_accuracy: 0.9286\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0504 - accuracy: 0.9756 - val_loss: 0.2573 - val_accuracy: 0.9286\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9286\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9286\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9286\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0484 - accuracy: 0.9756 - val_loss: 0.2786 - val_accuracy: 0.9286\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9286\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9286\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0479 - accuracy: 0.9756 - val_loss: 0.2969 - val_accuracy: 0.9286\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9286\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9286\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9286\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9286\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9286\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9286\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0462 - accuracy: 0.9756 - val_loss: 0.2830 - val_accuracy: 0.9286\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9286\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9286\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9286\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9286\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9286\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9286\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0418 - accuracy: 0.9756 - val_loss: 0.2750 - val_accuracy: 0.9286\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9286\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9286\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9286\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9286\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9286\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9286\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9286\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9286\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0426 - accuracy: 0.9756 - val_loss: 0.2953 - val_accuracy: 0.9286\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0425 - accuracy: 0.9756 - val_loss: 0.2760 - val_accuracy: 0.9286\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9286\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9286\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9286\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9286\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9286\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9286\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9286\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9286\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0408 - accuracy: 0.9756 - val_loss: 0.2649 - val_accuracy: 0.9286\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9286\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9286\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9286\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9286\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9286\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9286\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9286\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9286\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9286\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9286\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9286\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0381 - accuracy: 0.9756 - val_loss: 0.2502 - val_accuracy: 0.9286\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0547 - accuracy: 0.9756 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0500 - accuracy: 0.9756 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9286\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9286\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0372 - accuracy: 0.9756 - val_loss: 0.2636 - val_accuracy: 0.9286\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9286\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9286\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9286\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9286\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9286\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9286\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9286\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9286\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9286\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9286\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9286\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9286\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9286\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9286\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9286\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9286\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9286\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9286\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9286\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9286\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9286\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9286\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9286\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9286\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0476 - accuracy: 0.9756 - val_loss: 0.3184 - val_accuracy: 0.9286\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0378 - accuracy: 0.9756 - val_loss: 0.2191 - val_accuracy: 0.9286\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9286\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0428 - accuracy: 0.9756 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0336 - accuracy: 0.9756 - val_loss: 0.2140 - val_accuracy: 0.9286\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9286\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9286\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9286\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9286\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9286\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9286\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9286\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0379 - accuracy: 0.9756 - val_loss: 0.1639 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0384 - accuracy: 0.9756 - val_loss: 0.1999 - val_accuracy: 0.9286\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9286\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9286\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9286\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9286\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9286\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9286\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9286\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9286\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9286\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9286\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9286\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9286\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0424 - accuracy: 0.9756 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9286\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9286\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9286\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9286\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9286\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9286\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0471 - accuracy: 0.9756 - val_loss: 0.3342 - val_accuracy: 0.9286\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0329 - accuracy: 0.9756 - val_loss: 0.2142 - val_accuracy: 0.9286\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9286\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9286\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9286\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9286\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9286\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9286\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9286\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9286\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9286\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9286\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9286\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9286\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9286\n",
            "2/2 [==============================] - 1s 157ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDAmodel\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "DXsfsf9wccxf",
        "outputId": "a7e38b37-28cd-4f80-ecec-765fc0902a15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4548a9cea3e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNDAmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NDAmodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[-1].activation = None\n",
        "img_path = \"shrink/shrink_testdata/shrink_testdata16.jpg\"\n",
        "img_array = gc.get_img_array(img_path)\n",
        "last_conv_layer_name = \"conv2d_939\"\n",
        "heatmap = gc.make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "gc.save_and_display_gradcam(img_path, heatmap, cam_path=\"camNDA.jpg\")"
      ],
      "metadata": {
        "id": "0cspW796sCRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwoP3zhQ2-MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []"
      ],
      "metadata": {
        "id": "D59yy9084I2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  model = models[i]\n",
        "  model.layers[-1].activation = True\n",
        "  predict = model.predict(shrink_test_data)\n",
        "  prediction = np.argmax(predict,axis=1)\n",
        "  accuracy = sum(tl == prediction) / 41\n",
        "  accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "KvFH5y5csLQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ba9f6b-1818-436a-ecbe-4497d3207ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 151ms/step\n",
            "2/2 [==============================] - 0s 111ms/step\n",
            "2/2 [==============================] - 0s 101ms/step\n",
            "2/2 [==============================] - 0s 104ms/step\n",
            "2/2 [==============================] - 0s 104ms/step\n",
            "2/2 [==============================] - 0s 105ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6miPMBw2D8A",
        "outputId": "7a178762-4d46-4dd9-e490-bdb0013f85e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.024390243902439025,\n",
              " 0.0975609756097561,\n",
              " 0.0975609756097561,\n",
              " 0.07317073170731707,\n",
              " 0.07317073170731707,\n",
              " 0.04878048780487805]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDAmodel\n",
        "predict = model.predict(shrink_test_data)\n",
        "prediction = np.argmax(predict,axis=1)\n",
        "accuracy = sum(tl == prediction) / 41\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e19GVqZT2IAV",
        "outputId": "ffbf06cf-32f4-42c3-ad1e-311e193d6b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 158ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiZ9Zbsy5wP0",
        "outputId": "3c790feb-f7bd-4bd4-991c-e34b29dc996e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.024390243902439025,\n",
              " 0.0975609756097561,\n",
              " 0.0975609756097561,\n",
              " 0.07317073170731707,\n",
              " 0.07317073170731707,\n",
              " 0.04878048780487805,\n",
              " 0.07317073170731707]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = NDAmodel.predict(shrink_test_data)\n",
        "accuracy = sum(tl == prediction) / 41\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wc3JDYJ5yNT",
        "outputId": "89cf8edf-20ba-4c43-e724-eb32b1613f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 152ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07317073170731707"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label_name = []\n",
        "for i in range(len(l)):\n",
        "  nm = label_name[l[i]]\n",
        "  pred_label_name.append(nm)\n",
        "pred_label_name"
      ],
      "metadata": {
        "id": "uQh4l1Ry6PLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_label_name = []\n",
        "for i in range(len(test_label)):\n",
        "  nm = test_label_name[test_label[i]]\n",
        "  correct_label_name.append(nm)\n",
        "correct_label_name"
      ],
      "metadata": {
        "id": "IjrPyiNRWuWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_shrink = pd.DataFrame()\n",
        "df_shrink[\"Predict_Class\"] = pred_label_name\n",
        "df_shrink[\"True_Class\"] = correct_label_name\n",
        "print(pd.crosstab(df_shrink[\"Predict_Class\"], df_shrink[\"True_Class\"]))\n",
        "print(\"サンプル数：\", len(df_shrink[\"Predict_Class\"]))\n",
        "print(\"正解数：\", sum(df_shrink[\"Predict_Class\"] == df_shrink[\"True_Class\"]))"
      ],
      "metadata": {
        "id": "mls--vSSW1t6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}